{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "import re\n",
    "import struct\n",
    "\n",
    "# set GPU to invisible\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.VERSION)\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "_BUFFER_SIZE = 69137\n",
    "_BATCH_SIZE = 128\n",
    "INPUT_SHAPE = (64, 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data as `numpy` array from packed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_etl1(etl1_path):\n",
    "    \n",
    "    datasets = []\n",
    "    labels = []\n",
    "    \n",
    "    def unpack_dataset(path):\n",
    "        img_arr = []\n",
    "        label_arr = []\n",
    "        \n",
    "        f = open(path, 'rb')\n",
    "        while True:\n",
    "            s = f.read(2052)\n",
    "\n",
    "            if not len(s) == 2052:\n",
    "                print('[{}] Reach EOF, remain {} bytes unread.'.format(path, len(s)))\n",
    "                break;\n",
    "            record = struct.unpack('>H2sH6BI4H4B4x2016s4x', s)\n",
    "            # label at index 1\n",
    "            label = record[1].decode('ascii')\n",
    "\n",
    "            if ' ' in label: # remove spaces\n",
    "                label = label.replace(' ', '')\n",
    "            # image at index 18\n",
    "            iF = Image.frombytes('F', (64, 63), record[18], 'bit', 4)\n",
    "            np_img = np.array(iF, dtype=np.uint8) # np_img.shape = (63, 64)\n",
    "            np_img = cv2.resize(np_img, INPUT_SHAPE, interpolation=cv2.INTER_CUBIC)\n",
    "            np_img.reshape((1, INPUT_SHAPE[0], INPUT_SHAPE[1]))\n",
    "            scaled_img = np_img.astype(np.float) / 15.0\n",
    "            \n",
    "            img_arr.append(scaled_img)\n",
    "            label_arr.append(label)\n",
    "\n",
    "        f.close()\n",
    "        \n",
    "        return img_arr, label_arr\n",
    "    \n",
    "    # we only need the katakana characters\n",
    "    skip_etls = [\n",
    "        'ETL1C_01',\n",
    "        'ETL1C_02',\n",
    "        'ETL1C_03',\n",
    "        'ETL1C_04',\n",
    "        'ETL1C_05',\n",
    "        'ETL1C_06',\n",
    "    ]\n",
    "    if not os.path.exists(etl1_path):\n",
    "        print('Invalid path')\n",
    "        return None\n",
    "    \n",
    "    etl1_files = os.listdir(etl1_path)\n",
    "    \n",
    "    for etl in etl1_files:\n",
    "        if not re.search('ETL1C_\\d\\d', etl) == None:\n",
    "            if etl in skip_etls:\n",
    "                continue\n",
    "            etl_path = os.path.join(etl1_path, etl)\n",
    "            \n",
    "            img_arr, label_arr = unpack_dataset(etl_path)\n",
    "            datasets.extend(img_arr)\n",
    "            labels.extend(label_arr)\n",
    "            \n",
    "    return (np.array(datasets), np.array(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the datasets as `tf.data.Dataset` from unpacked data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_etl_datasets():\n",
    "    data_root = pathlib.Path('./etlcb_01_datasets/')\n",
    "    all_image_paths = list(data_root.glob('*/*'))\n",
    "    all_image_paths = [str(path) for path in all_image_paths]\n",
    "\n",
    "    label_names = sorted(\n",
    "        item.name for item in data_root.glob('*/') if item.is_dir())\n",
    "    label_to_index = dict((name, index)\n",
    "                         for index, name in enumerate(label_names))\n",
    "\n",
    "    all_image_labels = [label_to_index[pathlib.Path(path).parent.name]\n",
    "                        for path in all_image_paths]\n",
    "\n",
    "    def process_image(img):\n",
    "        img = tf.image.decode_png(img, channels=1)\n",
    "        img = tf.image.resize_images(img, [64, 64])\n",
    "\n",
    "        img /= 255.0\n",
    "        return img\n",
    "\n",
    "    def load_and_process_image(path):\n",
    "        img = tf.read_file(path)\n",
    "        return process_image(img)\n",
    "\n",
    "    path_ds = tf.data.Dataset.from_tensor_slices(all_image_paths)\n",
    "    img_ds = path_ds.map(load_and_process_image, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "    label_ds = tf.data.Dataset.from_tensor_slices(\n",
    "        tf.cast(all_image_labels, tf.int64))\n",
    "\n",
    "    return img_ds, label_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_kana_cnn_model():\n",
    "    input_shape=(64, 64, 1, )\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Conv2D(filters=32, \n",
    "                            kernel_size=5,\n",
    "                            padding='same',\n",
    "                            activation=tf.nn.relu,\n",
    "                            input_shape=input_shape, \n",
    "                            data_format='channels_last', \n",
    "                            name='kana_conv1'),\n",
    "        keras.layers.MaxPooling2D(pool_size=2, \n",
    "                                  strides=2),\n",
    "        keras.layers.Conv2D(filters=64, \n",
    "                            kernel_size=5, \n",
    "                            padding='same', \n",
    "                            activation=tf.nn.relu, \n",
    "                            name='kana_conv2'),\n",
    "        keras.layers.MaxPooling2D(pool_size=2, \n",
    "                                  strides=2),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(1024, activation=tf.nn.relu),\n",
    "        keras.layers.Dense(46, activation=tf.nn.softmax)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def kana_keras_v2():\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Conv2D(\n",
    "            filters=32, \n",
    "            kernel_size=5, \n",
    "#             strides=2, \n",
    "            padding='same',\n",
    "            activation=tf.nn.relu,\n",
    "            input_shape=(64,64,1,), \n",
    "            data_format='channels_last'\n",
    "            ),\n",
    "        keras.layers.MaxPool2D(\n",
    "            pool_size=2, \n",
    "#             strides=(2, 2),\n",
    "            # padding='same'\n",
    "            ),\n",
    "        keras.layers.Conv2D(\n",
    "            filters=16, \n",
    "            kernel_size=5, \n",
    "#             strides=(2, 2), \n",
    "            padding='same',\n",
    "            activation=tf.nn.relu,\n",
    "            ),\n",
    "        keras.layers.MaxPool2D(\n",
    "            pool_size=(2, 2),\n",
    "#             strides=(2, 2), \n",
    "            # padding='same'\n",
    "            ),\n",
    "        keras.layers.Conv2D(\n",
    "            filters=16, \n",
    "            kernel_size=3, \n",
    "            padding='same',\n",
    "            activation=tf.nn.relu,\n",
    "            ),\n",
    "        keras.layers.MaxPool2D(\n",
    "            pool_size=2, \n",
    "#             strides=(2, 2)\n",
    "            ),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(\n",
    "            units=128, \n",
    "            activation=tf.nn.relu,\n",
    "            ),\n",
    "        keras.layers.Dense(\n",
    "            units=46,\n",
    "            activation=tf.nn.softmax\n",
    "        )\n",
    "    ])\n",
    "    return model\n",
    "model = kana_keras_v2()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_label = compile_etl_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kana_ds = tf.data.Dataset.zip((train_data, train_label))\n",
    "kana_ds.apply(tf.data.experimental.shuffle_and_repeat(buffer_size=_BUFFER_SIZE))\n",
    "kana_ds.batch(_BATCH_SIZE)\n",
    "kana_ds.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('output_shapes:', kana_ds.output_shapes)\n",
    "print('output_classes:', kana_ds.output_classes)\n",
    "print('output_types:', kana_ds.output_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(kana_ds, epochs=1, steps_per_epoch=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_ds = tf.data.Dataset.zip((train_data, train_label))\n",
    "img_ds = train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img_ds.output_classes)\n",
    "print(img_ds.output_shapes)\n",
    "print(img_ds.output_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_COUNT = 69137\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ds.cache().apply(tf.data.experimental.shuffle_and_repeat(buffer_size=IMG_COUNT))\n",
    "img_ds.batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Failed to feed data into the Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=train_data, y=train_label, epochs=5, steps_per_epoch=IMG_COUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Estimator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kana_estimator_fn(features, output):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[./ETL1/ETL1C_07] Reach EOF, remain 0 bytes unread.\n",
      "[./ETL1/ETL1C_08] Reach EOF, remain 0 bytes unread.\n",
      "[./ETL1/ETL1C_09] Reach EOF, remain 0 bytes unread.\n",
      "[./ETL1/ETL1C_10] Reach EOF, remain 0 bytes unread.\n",
      "[./ETL1/ETL1C_11] Reach EOF, remain 0 bytes unread.\n",
      "[./ETL1/ETL1C_12] Reach EOF, remain 0 bytes unread.\n",
      "[./ETL1/ETL1C_13] Reach EOF, remain 0 bytes unread.\n"
     ]
    }
   ],
   "source": [
    "datasets, labels = numpy_etl1('./ETL1/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(71959, 64, 64)\n",
      "(71959,)\n"
     ]
    }
   ],
   "source": [
    "print(datasets.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 60\n",
    "plt.imshow(datasets[idx])\n",
    "plt.title(labels[idx])\n",
    "plt.colorbar()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
